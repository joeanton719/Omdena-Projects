{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebooks contains data pre-processing of merged traffic density columns using Polars. \n",
    "##### * First, we will remove data for all GEOHASH that has less than 28k hours of data.\n",
    "##### * Then, we will transform the dataset to ensure every remaining GEOHASH location has 29,184 hours of data points. \n",
    "\n",
    "##### At present, for each GEOHASH, the DATE_TIME column is not in propert hour frequency. An exmaple will be shown soon.\n",
    "\n",
    "##### **Here is an article about [Pandas VS Polars](https://towardsdatascience.com/pandas-dataframe-but-much-faster-f475d6be4cd4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read Parquet file and choose only selected columns (Ignore date time features for now to save memory)\n",
    "\n",
    "selected_cols=['DATE_TIME', 'LATITUDE', 'LONGITUDE', 'GEOHASH', 'MINIMUM_SPEED', 'MAXIMUM_SPEED', 'AVERAGE_SPEED', 'NUMBER_OF_VEHICLES']\n",
    "\n",
    "raw_df = (\n",
    "    pl.read_parquet(\"datasets/01_tr_density/ist_traffic_density_rev01.gz\", columns=selected_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating a copy to save time in case the original dataset is needed\n",
    "all_df=raw_df.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>LATITUDE</th><th>LONGITUDE</th><th>GEOHASH</th><th>MINIMUM_SPEED</th><th>MAXIMUM_SPEED</th><th>AVERAGE_SPEED</th><th>NUMBER_OF_VEHICLES</th></tr><tr><td>datetime[ns]</td><td>f32</td><td>f32</td><td>str</td><td>u8</td><td>u8</td><td>u8</td><td>u16</td></tr></thead><tbody><tr><td>2020-01-01 00:00:00</td><td>41.080627</td><td>28.811646</td><td>&quot;sxk3xw&quot;</td><td>135</td><td>18</td><td>81</td><td>132</td></tr><tr><td>2020-01-01 00:00:00</td><td>40.987244</td><td>29.108276</td><td>&quot;sxk9nm&quot;</td><td>143</td><td>10</td><td>73</td><td>162</td></tr><tr><td>2020-01-01 00:00:00</td><td>41.003723</td><td>29.09729</td><td>&quot;sxk9q0&quot;</td><td>128</td><td>6</td><td>50</td><td>110</td></tr><tr><td>2020-01-01 00:00:00</td><td>40.99823</td><td>28.67981</td><td>&quot;sxk3hx&quot;</td><td>111</td><td>22</td><td>68</td><td>101</td></tr><tr><td>2020-01-01 00:00:00</td><td>41.042175</td><td>28.02063</td><td>&quot;sx7cmx&quot;</td><td>99</td><td>99</td><td>99</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌────────────┬───────────┬───────────┬─────────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ DATE_TIME  ┆ LATITUDE  ┆ LONGITUDE ┆ GEOHASH ┆ MINIMUM_SP ┆ MAXIMUM_SP ┆ AVERAGE_SP ┆ NUMBER_OF_ │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---     ┆ EED        ┆ EED        ┆ EED        ┆ VEHICLES   │\n",
       "│ datetime[n ┆ f32       ┆ f32       ┆ str     ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│ s]         ┆           ┆           ┆         ┆ u8         ┆ u8         ┆ u8         ┆ u16        │\n",
       "╞════════════╪═══════════╪═══════════╪═════════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 2020-01-01 ┆ 41.080627 ┆ 28.811646 ┆ sxk3xw  ┆ 135        ┆ 18         ┆ 81         ┆ 132        │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 40.987244 ┆ 29.108276 ┆ sxk9nm  ┆ 143        ┆ 10         ┆ 73         ┆ 162        │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.003723 ┆ 29.09729  ┆ sxk9q0  ┆ 128        ┆ 6          ┆ 50         ┆ 110        │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 40.99823  ┆ 28.67981  ┆ sxk3hx  ┆ 111        ┆ 22         ┆ 68         ┆ 101        │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.042175 ┆ 28.02063  ┆ sx7cmx  ┆ 99         ┆ 99         ┆ 99         ┆ 1          │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "└────────────┴───────────┴───────────┴─────────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column information:\n",
      "DATE_TIME: Datetime(time_unit='ns', time_zone=None)\n",
      "LATITUDE: Float32\n",
      "LONGITUDE: Float32\n",
      "GEOHASH: Utf8\n",
      "MINIMUM_SPEED: UInt8\n",
      "MAXIMUM_SPEED: UInt8\n",
      "AVERAGE_SPEED: UInt8\n",
      "NUMBER_OF_VEHICLES: UInt16\n",
      "\n",
      "Number of rows: 66146858\n",
      "\n",
      "Size (bytes): 2.156 gb\n"
     ]
    }
   ],
   "source": [
    "# Get column information\n",
    "column_info = all_df.schema\n",
    "\n",
    "# Get data types information\n",
    "data_types = all_df.dtypes\n",
    "\n",
    "# Get number of rows\n",
    "num_rows = all_df.height\n",
    "\n",
    "# Estimate size of the DataFrame\n",
    "size_bytes = all_df.estimated_size(unit='gb')\n",
    "\n",
    "# Display the information\n",
    "print(\"Column information:\")\n",
    "for key, value in column_info.items():\n",
    "    print(key + ':', value)\n",
    "print()\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print()\n",
    "print(\"Size (bytes):\", np.round(size_bytes, 3), \"gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating a seperate dataframe that shows all unique GEOHASH and the cooresponding count of rows. \n",
    "# Followed by creating percentage of rows available compared to total number of hours from \n",
    "# Jan 2020 to April 2023 (29,184 hours)\n",
    "\n",
    "geohash_hrs = all_df.groupby('GEOHASH').count()\n",
    "perc = pl.Series('perc', np.round(100*(geohash_hrs['count']/29184), 3))\n",
    "geohash_hrs = geohash_hrs.with_columns(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_813, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>GEOHASH</th><th>count</th><th>perc</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;sxk3he&quot;</td><td>28017</td><td>96.001</td></tr><tr><td>&quot;sxk9w1&quot;</td><td>28017</td><td>96.001</td></tr><tr><td>&quot;sxkd8d&quot;</td><td>28018</td><td>96.005</td></tr><tr><td>&quot;sxk9tb&quot;</td><td>28025</td><td>96.029</td></tr><tr><td>&quot;sxk9tf&quot;</td><td>28026</td><td>96.032</td></tr><tr><td>&quot;sxk8yd&quot;</td><td>28027</td><td>96.035</td></tr><tr><td>&quot;sxk4rx&quot;</td><td>28027</td><td>96.035</td></tr><tr><td>&quot;sxk3sd&quot;</td><td>28027</td><td>96.035</td></tr><tr><td>&quot;sxkbut&quot;</td><td>28029</td><td>96.042</td></tr><tr><td>&quot;sxk9zj&quot;</td><td>28032</td><td>96.053</td></tr><tr><td>&quot;sxk6rb&quot;</td><td>28035</td><td>96.063</td></tr><tr><td>&quot;sxkb75&quot;</td><td>28041</td><td>96.083</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;sxk9fc&quot;</td><td>28512</td><td>97.697</td></tr><tr><td>&quot;sxk3rx&quot;</td><td>28513</td><td>97.701</td></tr><tr><td>&quot;sxk90n&quot;</td><td>28513</td><td>97.701</td></tr><tr><td>&quot;sxk90w&quot;</td><td>28513</td><td>97.701</td></tr><tr><td>&quot;sxk96q&quot;</td><td>28513</td><td>97.701</td></tr><tr><td>&quot;sxk3x8&quot;</td><td>28514</td><td>97.704</td></tr><tr><td>&quot;sxk3xe&quot;</td><td>28514</td><td>97.704</td></tr><tr><td>&quot;sxk3py&quot;</td><td>28514</td><td>97.704</td></tr><tr><td>&quot;sxk3rs&quot;</td><td>28514</td><td>97.704</td></tr><tr><td>&quot;sxk3nk&quot;</td><td>28515</td><td>97.708</td></tr><tr><td>&quot;sxk3r9&quot;</td><td>28515</td><td>97.708</td></tr><tr><td>&quot;sxk3nt&quot;</td><td>28516</td><td>97.711</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_813, 3)\n",
       "┌─────────┬───────┬────────┐\n",
       "│ GEOHASH ┆ count ┆ perc   │\n",
       "│ ---     ┆ ---   ┆ ---    │\n",
       "│ str     ┆ u32   ┆ f64    │\n",
       "╞═════════╪═══════╪════════╡\n",
       "│ sxk3he  ┆ 28017 ┆ 96.001 │\n",
       "│ sxk9w1  ┆ 28017 ┆ 96.001 │\n",
       "│ sxkd8d  ┆ 28018 ┆ 96.005 │\n",
       "│ sxk9tb  ┆ 28025 ┆ 96.029 │\n",
       "│ …       ┆ …     ┆ …      │\n",
       "│ sxk3rs  ┆ 28514 ┆ 97.704 │\n",
       "│ sxk3nk  ┆ 28515 ┆ 97.708 │\n",
       "│ sxk3r9  ┆ 28515 ┆ 97.708 │\n",
       "│ sxk3nt  ┆ 28516 ┆ 97.711 │\n",
       "└─────────┴───────┴────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking GEOHASH with atleast 96% non null rows. The corresponsing number of available data is displayed \n",
    "# in the `count` column\n",
    "geohash_hrs.filter(pl.col('perc') > 96).sort('perc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sxk3he', 'sxk9w1', 'sxkd8d', ..., 'sxk3nk', 'sxk3r9', 'sxk3nt'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving those GEOHASH with 96% hours of data\n",
    "selected_gh = np.array(geohash_hrs.filter(pl.col('perc') > 96).sort('perc')['GEOHASH'])\n",
    "selected_gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filtering out GEOHASH\n",
    "\n",
    "filtered_df = (\n",
    "    all_df.filter(pl.col('GEOHASH').is_in(selected_gh))\n",
    "    .set_sorted(['DATE_TIME', 'GEOHASH'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51548379"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows reduced from 66+ million records to 51.5 million records\n",
    "# The number of rows in the filtered dataset will increase again laterwards when ensuring the \n",
    "# DATE_TIME for all GEOHASH is of hourly frequency\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>GEOHASH</th><th>DATE_TIME</th></tr><tr><td>str</td><td>datetime[ns]</td></tr></thead><tbody><tr><td>&quot;sx7cm5&quot;</td><td>2020-01-01 02:00:00</td></tr><tr><td>&quot;sx7ckc&quot;</td><td>2020-01-01 02:00:00</td></tr><tr><td>&quot;sxk6ru&quot;</td><td>2020-01-01 00:00:00</td></tr><tr><td>&quot;sxk904&quot;</td><td>2020-01-01 00:00:00</td></tr><tr><td>&quot;sxk961&quot;</td><td>2020-01-01 00:00:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────┬─────────────────────┐\n",
       "│ GEOHASH ┆ DATE_TIME           │\n",
       "│ ---     ┆ ---                 │\n",
       "│ str     ┆ datetime[ns]        │\n",
       "╞═════════╪═════════════════════╡\n",
       "│ sx7cm5  ┆ 2020-01-01 02:00:00 │\n",
       "│ sx7ckc  ┆ 2020-01-01 02:00:00 │\n",
       "│ sxk6ru  ┆ 2020-01-01 00:00:00 │\n",
       "│ sxk904  ┆ 2020-01-01 00:00:00 │\n",
       "│ sxk961  ┆ 2020-01-01 00:00:00 │\n",
       "└─────────┴─────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether all GEOHASH has start DATE_TIME as \"2020-01-01 00:00:00\"\n",
    "gh_hr_1 = filtered_df.groupby('GEOHASH').agg(pl.col('DATE_TIME').first()).sort(\"DATE_TIME\", descending=True)\n",
    "gh_hr_1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the above dataframe shows that 2 GEOHASH has start datetime at 02:00 hours instead of 00:00 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we will transform the dataset to ensure hourly frequency across all GEOHASH. \n",
    "# There will be null values for some of the rows as a result. These will be filled in using appropriate methods later.\n",
    "\n",
    "# NOTE: For Some GEOHASH, the first hour of data starts from 02:00 hours intead of 00:00 hours.\n",
    "# In order to fix this and ensure every single day has 24 hours of data, we will use offset argument and\n",
    "# filter out rows\n",
    "\n",
    "df = (\n",
    "    # Groupby GEOHASH and upsample by DATE_TIME by 1 hour. Offset the first rows by 2 hours\n",
    "    filtered_df.upsample(time_column='DATE_TIME', by='GEOHASH', every=\"1h\", offset=\"-2h\")\n",
    "\n",
    "    # keep rows only from 1 Jan 2020 00:00 hours  \n",
    "    .filter(pl.col('DATE_TIME') > datetime(2019, 12, 31, 23))\n",
    "\n",
    "    # first backward fill, then forward fill null values for GEOHASH and coordinates\n",
    "    .with_columns(pl.col(['GEOHASH', 'LATITUDE', 'LONGITUDE']).backward_fill().forward_fill())\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the above transformation, pandas took 2min 23s, while polars only took 19.9 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>LATITUDE</th><th>LONGITUDE</th><th>GEOHASH</th><th>MINIMUM_SPEED</th><th>MAXIMUM_SPEED</th><th>AVERAGE_SPEED</th><th>NUMBER_OF_VEHICLES</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1362213</td><td>1362213</td><td>1362213</td><td>1362213</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌───────────┬──────────┬───────────┬─────────┬────────────┬────────────┬────────────┬──────────────┐\n",
       "│ DATE_TIME ┆ LATITUDE ┆ LONGITUDE ┆ GEOHASH ┆ MINIMUM_SP ┆ MAXIMUM_SP ┆ AVERAGE_SP ┆ NUMBER_OF_VE │\n",
       "│ ---       ┆ ---      ┆ ---       ┆ ---     ┆ EED        ┆ EED        ┆ EED        ┆ HICLES       │\n",
       "│ u32       ┆ u32      ┆ u32       ┆ u32     ┆ ---        ┆ ---        ┆ ---        ┆ ---          │\n",
       "│           ┆          ┆           ┆         ┆ u32        ┆ u32        ┆ u32        ┆ u32          │\n",
       "╞═══════════╪══════════╪═══════════╪═════════╪════════════╪════════════╪════════════╪══════════════╡\n",
       "│ 0         ┆ 0        ┆ 0         ┆ 0       ┆ 1362213    ┆ 1362213    ┆ 1362213    ┆ 1362213      │\n",
       "└───────────┴──────────┴───────────┴─────────┴────────────┴────────────┴────────────┴──────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are about 1.3 million rows of missing values in total\n",
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52910592"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of rows has increased from approximatly 51.5 million rows for the filtered \n",
    "# dataset to 52.9 million rows for the transformed dataset\n",
    "# 29184 hours * 1813 GEOHASH = 52,910,592 hours of data \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>LATITUDE</th><th>LONGITUDE</th><th>GEOHASH</th><th>MINIMUM_SPEED</th><th>MAXIMUM_SPEED</th><th>AVERAGE_SPEED</th><th>NUMBER_OF_VEHICLES</th></tr><tr><td>datetime[ns]</td><td>f32</td><td>f32</td><td>str</td><td>u8</td><td>u8</td><td>u8</td><td>u16</td></tr></thead><tbody><tr><td>2020-01-01 00:00:00</td><td>41.053162</td><td>29.09729</td><td>&quot;sxk9w1&quot;</td><td>46</td><td>7</td><td>24</td><td>7</td></tr><tr><td>2020-01-01 01:00:00</td><td>41.053162</td><td>29.09729</td><td>&quot;sxk9w1&quot;</td><td>25</td><td>17</td><td>21</td><td>2</td></tr><tr><td>2020-01-01 02:00:00</td><td>41.053162</td><td>29.09729</td><td>&quot;sxk9w1&quot;</td><td>44</td><td>15</td><td>29</td><td>5</td></tr><tr><td>2020-01-01 03:00:00</td><td>41.053162</td><td>29.09729</td><td>&quot;sxk9w1&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2020-01-01 04:00:00</td><td>41.053162</td><td>29.09729</td><td>&quot;sxk9w1&quot;</td><td>61</td><td>9</td><td>33</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌────────────┬───────────┬───────────┬─────────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ DATE_TIME  ┆ LATITUDE  ┆ LONGITUDE ┆ GEOHASH ┆ MINIMUM_SP ┆ MAXIMUM_SP ┆ AVERAGE_SP ┆ NUMBER_OF_ │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---     ┆ EED        ┆ EED        ┆ EED        ┆ VEHICLES   │\n",
       "│ datetime[n ┆ f32       ┆ f32       ┆ str     ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│ s]         ┆           ┆           ┆         ┆ u8         ┆ u8         ┆ u8         ┆ u16        │\n",
       "╞════════════╪═══════════╪═══════════╪═════════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 2020-01-01 ┆ 41.053162 ┆ 29.09729  ┆ sxk9w1  ┆ 46         ┆ 7          ┆ 24         ┆ 7          │\n",
       "│ 00:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.053162 ┆ 29.09729  ┆ sxk9w1  ┆ 25         ┆ 17         ┆ 21         ┆ 2          │\n",
       "│ 01:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.053162 ┆ 29.09729  ┆ sxk9w1  ┆ 44         ┆ 15         ┆ 29         ┆ 5          │\n",
       "│ 02:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.053162 ┆ 29.09729  ┆ sxk9w1  ┆ null       ┆ null       ┆ null       ┆ null       │\n",
       "│ 03:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01-01 ┆ 41.053162 ┆ 29.09729  ┆ sxk9w1  ┆ 61         ┆ 9          ┆ 33         ┆ 5          │\n",
       "│ 04:00:00   ┆           ┆           ┆         ┆            ┆            ┆            ┆            │\n",
       "└────────────┴───────────┴───────────┴─────────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of null values\n",
    "df.filter(pl.col('GEOHASH')=='sxk9w1').head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen from the above sample of the dataset for GEOHASH='sxk9w1' (same as shown earlier), now there is a row of 03:00 hours. The corresponding values for speed and num_of_vehicles is null. We will handle missing values in the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall, Polars is a much more efficient library to handle large datasets such as this one. Polars beats pandas in every task done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_813, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>GEOHASH</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;sxk6mw&quot;</td><td>29184</td></tr><tr><td>&quot;sxk3kf&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9ub&quot;</td><td>29184</td></tr><tr><td>&quot;sxkb8x&quot;</td><td>29184</td></tr><tr><td>&quot;sxkf26&quot;</td><td>29184</td></tr><tr><td>&quot;sxkceq&quot;</td><td>29184</td></tr><tr><td>&quot;sxkc2z&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9wn&quot;</td><td>29184</td></tr><tr><td>&quot;sxk3r4&quot;</td><td>29184</td></tr><tr><td>&quot;sxk396&quot;</td><td>29184</td></tr><tr><td>&quot;sxkd2u&quot;</td><td>29184</td></tr><tr><td>&quot;sxkc23&quot;</td><td>29184</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;sxk33g&quot;</td><td>29184</td></tr><tr><td>&quot;sxk91s&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9me&quot;</td><td>29184</td></tr><tr><td>&quot;sxk1u6&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9nw&quot;</td><td>29184</td></tr><tr><td>&quot;sxk3bs&quot;</td><td>29184</td></tr><tr><td>&quot;sxk3kd&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9n2&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9f8&quot;</td><td>29184</td></tr><tr><td>&quot;sxk3he&quot;</td><td>29184</td></tr><tr><td>&quot;sxk9wm&quot;</td><td>29184</td></tr><tr><td>&quot;sxk656&quot;</td><td>29184</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_813, 2)\n",
       "┌─────────┬───────┐\n",
       "│ GEOHASH ┆ count │\n",
       "│ ---     ┆ ---   │\n",
       "│ str     ┆ u32   │\n",
       "╞═════════╪═══════╡\n",
       "│ sxk6mw  ┆ 29184 │\n",
       "│ sxk3kf  ┆ 29184 │\n",
       "│ sxk9ub  ┆ 29184 │\n",
       "│ sxkb8x  ┆ 29184 │\n",
       "│ …       ┆ …     │\n",
       "│ sxk9f8  ┆ 29184 │\n",
       "│ sxk3he  ┆ 29184 │\n",
       "│ sxk9wm  ┆ 29184 │\n",
       "│ sxk656  ┆ 29184 │\n",
       "└─────────┴───────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All GEOHASH have 29184 rows of data\n",
    "df.groupby('GEOHASH').count().sort('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to parquet format with zstd compression\n",
    "df.write_parquet(\"datasets/01_tr_density/ist_traffic_density_rev02.zstd\", compression='zstd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
