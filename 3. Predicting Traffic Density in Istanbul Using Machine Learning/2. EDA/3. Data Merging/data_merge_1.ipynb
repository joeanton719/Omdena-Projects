{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citizen and Tourist Travel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cz_path=\"datasets/02_tr_tourist_citizen_monthlytravel/\"\n",
    "\n",
    "tr_df = (\n",
    "    # Read CSV\n",
    "    pl.read_csv(tr_cz_path+\"tourist_monthly_arrivals.csv\", columns=[\"TOTAL\", \"month\", \"year\"])\n",
    "\n",
    "    # Rename columns\n",
    "    .rename({\"month\" : \"MONTH\", \"year\" : \"YEAR\", \"TOTAL\" : \"TOURIST_ARRIVAL\"})\n",
    "\n",
    "    # Downcast datatypes\n",
    "    .with_columns(pl.col(\"YEAR\").cast(pl.UInt16),\n",
    "                  pl.col(\"MONTH\").cast(pl.UInt8),\n",
    "                  pl.col(\"TOURIST_ARRIVAL\").cast(pl.UInt32))\n",
    ")\n",
    "\n",
    "cz_df = (\n",
    "    # Read CSV\n",
    "    pl.read_csv(tr_cz_path+\"citizen_travel_df.csv\")\n",
    "\n",
    "    # Group by columns\n",
    "    .groupby([\"year\", \"citizen_travel_type\", \"month\"],maintain_order=True)\n",
    "\n",
    "    # aggregate column by sum\n",
    "    .agg(pl.col(\"number_of_people\").sum())\n",
    "\n",
    "    # Pivot to convert `citizen_travel_type` categories to columns\n",
    "    .pivot(columns=\"citizen_travel_type\", \n",
    "           values=\"number_of_people\", \n",
    "           index=[\"year\", \"month\"],\n",
    "           aggregate_function=\"sum\")\n",
    "\n",
    "    # Rename columns\n",
    "    .rename({\"year\" : \"YEAR\", \"month\" : \"MONTH\", \"Returning\" : \"CITIZEN_RETURN\", \"Travelling Abroad\" : \"CITIZEN_ARRIVAL\"})\n",
    "\n",
    "    # Downcast datatypes\n",
    "    .with_columns(pl.col(\"YEAR\").cast(pl.UInt16),\n",
    "                  pl.col(\"MONTH\").cast(pl.UInt8),\n",
    "                  pl.col([\"CITIZEN_RETURN\", \"CITIZEN_ARRIVAL\"]).cast(pl.UInt32))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holidays & Observances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2020, 5, 23), datetime.date(2021, 5, 12), datetime.date(2022, 5, 1), datetime.date(2023, 4, 20)]\n",
      "['date', 'holiday_name', 'holiday_type']\n"
     ]
    }
   ],
   "source": [
    "hol_df = (\n",
    "    # Read CSV\n",
    "    pl.read_csv(\"datasets/06_tr_holidays_obs/tr_holidays_obs.csv\")\n",
    "\n",
    "    # Convert datestring to date datatype\n",
    "    .with_columns(pl.col(\"date\")\n",
    "                  .str.to_datetime(\"%Y-%m-%d\")\n",
    "                  .dt\n",
    "                  .date())\n",
    "\n",
    "    # Filter out data before 2020\n",
    "    .filter(pl.col(\"date\").dt.year()>=2020)\n",
    ")\n",
    "\n",
    "# There are no information about ramadan start date. \n",
    "# Adding Ramdan start date, create a seperate dataframe and then append to hol_df\n",
    "ramadan_hol_start = (\n",
    "    hol_df.filter((pl.col(\"holiday_type\")==\"Half Day\") &\n",
    "                  (pl.col(\"holiday_name\")=='Ramadan Feast Eve'))['date']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "print(ramadan_hol_start)\n",
    "print(hol_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2020, 4, 24),\n",
       " datetime.date(2021, 4, 13),\n",
       " datetime.date(2022, 4, 2),\n",
       " datetime.date(2023, 3, 23)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Ramadan Start dates list\n",
    "ramadan_start =[]\n",
    "\n",
    "for val in [\"2020-04-24\", \"2021-04-13\", \"2022-04-02\", \"2023-03-23\"]:\n",
    "    ramadan_start.append(datetime.strptime(val, \"%Y-%m-%d\").date())\n",
    "\n",
    "ramadan_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Ramadan days Dataframe\n",
    "ramadan_list = []\n",
    "\n",
    "for sd, ed in zip(ramadan_start, ramadan_hol_start):\n",
    "    date_range = pl.date_range(start=sd, end=ed, interval='1d', closed=\"left\", eager=True).to_list()\n",
    "\n",
    "    for date in date_range:\n",
    "        ramadan_list.append({\n",
    "            'date' : date,\n",
    "            'holiday_name' : 'Ramadan Observance',\n",
    "            'holiday_type' : 'Ramadan Observance'\n",
    "        })\n",
    "\n",
    "ramadan_df = pl.DataFrame(ramadan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE</th><th>HOLIDAY_NAME</th><th>HOLIDAY_TYPE</th></tr><tr><td>date</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2020-01-01</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td></tr><tr><td>2020-03-20</td><td>&quot;March Equinox&quot;</td><td>&quot;Season&quot;</td></tr><tr><td>2020-04-23</td><td>&quot;National Sover…</td><td>&quot;National holid…</td></tr><tr><td>2020-04-24</td><td>&quot;Ramadan Observ…</td><td>&quot;Ramadan Observ…</td></tr><tr><td>2020-04-25</td><td>&quot;Ramadan Observ…</td><td>&quot;Ramadan Observ…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────────┬───────────────────────────────────┬────────────────────┐\n",
       "│ DATE       ┆ HOLIDAY_NAME                      ┆ HOLIDAY_TYPE       │\n",
       "│ ---        ┆ ---                               ┆ ---                │\n",
       "│ date       ┆ str                               ┆ str                │\n",
       "╞════════════╪═══════════════════════════════════╪════════════════════╡\n",
       "│ 2020-01-01 ┆ New Year's Day                    ┆ National holiday   │\n",
       "│ 2020-03-20 ┆ March Equinox                     ┆ Season             │\n",
       "│ 2020-04-23 ┆ National Sovereignty and Childre… ┆ National holiday   │\n",
       "│ 2020-04-24 ┆ Ramadan Observance                ┆ Ramadan Observance │\n",
       "│ 2020-04-25 ┆ Ramadan Observance                ┆ Ramadan Observance │\n",
       "└────────────┴───────────────────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending to hol_df\n",
    "hol_df = (\n",
    "    pl.concat([hol_df, ramadan_df])\n",
    "    .sort('date', 'holiday_name')\n",
    "\n",
    "    # Some dates have two events, One Ramadan observance and national holiday. \n",
    "    # Keep only national rows for these dates\n",
    "    .groupby('date').first()\n",
    "    .rename({'holiday_name' : 'HOLIDAY_NAME', 'holiday_type' : 'HOLIDAY_TYPE', 'date' : 'DATE'})\n",
    ")\n",
    "\n",
    "hol_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### School Holidays\n",
    "    Similar to ramadan, a dataframe with all school holidays with dates will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Youth and Sports Day',\n",
       " 'Labour Day',\n",
       " 'National Sovereignty Holiday',\n",
       " 'Ramadan Holiday',\n",
       " 'Republic of Türkiye Day',\n",
       " 'National sovereignty and the child',\n",
       " 'holiday of youth',\n",
       " 'Christmas holidays']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single day school holidays\n",
    "sch_hol_1 = (\n",
    "    pl.read_csv(\"datasets/07_tr_ist_school_holidays/tr_ist_school_holidays.csv\")\n",
    "    .filter(pl.col('end').is_null())\n",
    "    .drop('end')\n",
    "    .with_columns(pl.col('start')\n",
    "                  .str.to_datetime(\"%Y-%m-%d\")\n",
    "                  .dt.date())\n",
    "    .rename({'start':'DATE', 'reason' : 'SCHOOL_HOLIDAY_TYPE'})\n",
    ")\n",
    "\n",
    "sch_hol_1['SCHOOL_HOLIDAY_TYPE'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Easter holidays_2021': {'start': '2021-04-12', 'end': '2021-04-16'},\n",
       " 'Schools closed (possibly distance learning) Covid-19_2020': {'start': '2020-03-16',\n",
       "  'end': '2020-03-22'},\n",
       " \"Fest des Fastenbrechens ('Id al Fitr)_2020\": {'start': '2020-05-24',\n",
       "  'end': '2020-05-26'},\n",
       " 'Summer holidays_2020': {'start': '2020-06-22', 'end': '2020-08-30'},\n",
       " 'Feast of the Breaking of the Fast_2021': {'start': '2021-05-13',\n",
       "  'end': '2021-05-15'},\n",
       " 'Spring time holidays_2022': {'start': '2022-04-11', 'end': '2022-04-15'},\n",
       " 'Spring time holidays_2023': {'start': '2023-04-15', 'end': '2023-04-20'},\n",
       " 'Sport holiday_2022': {'start': '2022-01-24', 'end': '2022-02-04'},\n",
       " 'Ramadan Holiday_2022': {'start': '2022-05-03', 'end': '2022-05-05'},\n",
       " 'Christmas holidays_2022': {'start': '2022-12-31', 'end': '2023-01-01'},\n",
       " 'Christmas holidays_2023': {'start': '2023-12-31', 'end': '2024-01-01'},\n",
       " 'Summer holidays_2022': {'start': '2022-06-17', 'end': '2022-09-11'},\n",
       " 'Sport holiday_2023': {'start': '2023-01-21', 'end': '2023-02-05'},\n",
       " 'November vacation_2023': {'start': '2023-11-11', 'end': '2023-11-19'},\n",
       " 'November vacation_2021': {'start': '2021-11-15', 'end': '2021-11-19'},\n",
       " 'Sport holiday_2020': {'start': '2020-01-20', 'end': '2020-01-31'},\n",
       " 'Spring time holidays_2020': {'start': '2020-04-06', 'end': '2020-04-10'},\n",
       " 'November vacation_2020': {'start': '2020-11-16', 'end': '2020-11-20'},\n",
       " 'Summer holidays_2021': {'start': '2021-06-19', 'end': '2021-09-12'},\n",
       " 'Summer holidays_2023': {'start': '2023-06-17', 'end': '2023-09-10'},\n",
       " 'Sport holiday_2021': {'start': '2021-01-25', 'end': '2021-02-05'},\n",
       " 'November vacation_2022': {'start': '2022-11-12', 'end': '2022-11-20'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary with school holidays as keys and holidays starting and ending days as sub-dictionaries\n",
    "sch_hol_dict = (\n",
    "    pl.read_csv(\"datasets/07_tr_ist_school_holidays/tr_ist_school_holidays.csv\")\n",
    "    .filter(pl.col('end').is_not_null())\n",
    "    .with_columns(pl.col('start').str.extract(r'^(\\d{4})-').alias(\"year\"))\n",
    "    .with_columns(pl.concat_str('reason', 'year', separator=\"_\"))\n",
    "    .drop('year')\n",
    "    .unique()\n",
    "    .select(['reason', 'start', 'end'])\n",
    "    .to_pandas()\n",
    "    .set_index('reason')\n",
    "    .T.to_dict()\n",
    ")\n",
    "\n",
    "sch_hol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Winter holidays',\n",
       " 'Schools closed (possibly distance learning) Covid-19',\n",
       " 'November vacation',\n",
       " 'Summer holidays',\n",
       " 'Easter holidays',\n",
       " 'Ramadan Holiday',\n",
       " 'Spring time holidays',\n",
       " 'Eid Holiday',\n",
       " 'Christmas holidays']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a single df with all school holidays that has starting and ending dates.\n",
    "school_hol_list = []\n",
    "\n",
    "for name in sch_hol_dict:\n",
    "    sd = datetime.strptime(sch_hol_dict[name]['start'], \"%Y-%m-%d\").date()\n",
    "    ed = datetime.strptime(sch_hol_dict[name]['end'], \"%Y-%m-%d\").date()\n",
    "    \n",
    "    date_range = pl.date_range(start=sd, end=ed, interval='1d', eager=True).to_list()\n",
    "\n",
    "    for date in date_range:\n",
    "        school_hol_list.append({\n",
    "            'DATE' : date,\n",
    "            'SCHOOL_HOLIDAY_TYPE' : name,\n",
    "        })\n",
    "\n",
    "sch_hol_2 = (\n",
    "    pl.DataFrame(school_hol_list)\n",
    "    .with_columns(pl.col('SCHOOL_HOLIDAY_TYPE')\n",
    "                  .str.extract(r'^(.+)_\\d{4}$')\n",
    "                  .str.replace(\"Sport holiday\", \"Winter holidays\")\n",
    "                  .str.replace(r\"Fest des Fastenbrechens \\('Id al Fitr\\)|Feast of the Breaking of the Fast\", \"Eid Holiday\")\n",
    "                  .str.replace(\"National sovereignty and the child\", \"National Sovereignty Holiday\"))\n",
    ")\n",
    "\n",
    "sch_hol_2['SCHOOL_HOLIDAY_TYPE'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE</th><th>SCHOOL_HOLIDAY_TYPE</th></tr><tr><td>date</td><td>str</td></tr></thead><tbody><tr><td>2020-01-01</td><td>&quot;Christmas holi…</td></tr><tr><td>2020-01-20</td><td>&quot;Winter holiday…</td></tr><tr><td>2020-01-21</td><td>&quot;Winter holiday…</td></tr><tr><td>2020-01-22</td><td>&quot;Winter holiday…</td></tr><tr><td>2020-01-23</td><td>&quot;Winter holiday…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬─────────────────────┐\n",
       "│ DATE       ┆ SCHOOL_HOLIDAY_TYPE │\n",
       "│ ---        ┆ ---                 │\n",
       "│ date       ┆ str                 │\n",
       "╞════════════╪═════════════════════╡\n",
       "│ 2020-01-01 ┆ Christmas holidays  │\n",
       "│ 2020-01-20 ┆ Winter holidays     │\n",
       "│ 2020-01-21 ┆ Winter holidays     │\n",
       "│ 2020-01-22 ┆ Winter holidays     │\n",
       "│ 2020-01-23 ┆ Winter holidays     │\n",
       "└────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging to one dataset\n",
    "all_school_holidays = (\n",
    "    pl.concat([sch_hol_2, sch_hol_1])\n",
    "    .sort('DATE')\n",
    "    .filter(pl.col('DATE').lt(datetime(2023, 5, 1)))\n",
    ")\n",
    "\n",
    "all_school_holidays.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Transport Passengers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### At present, the public transport passenger dataset is not of hourly frequency. Therefore the following pre-processing steps will be done:\n",
    "    * groupby date and road_type and take sum of total passengers\n",
    "    * pivot the dataset to convert road_type categories as column\n",
    "    * Resample the dataset at 1 hour frequency to get 29,184 total rows \n",
    "    * interpolate the data (similar to what was done to traffic density dataset) to fill missing values\n",
    "    * Finally, sorting the data by datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>transition_date</th><th>HIGHWAY</th><th>SEA</th><th>RAIL</th></tr><tr><td>datetime[ns]</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>2023-04-30 23:00:00</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌─────────────────────┬─────────┬──────┬──────┐\n",
       "│ transition_date     ┆ HIGHWAY ┆ SEA  ┆ RAIL │\n",
       "│ ---                 ┆ ---     ┆ ---  ┆ ---  │\n",
       "│ datetime[ns]        ┆ u32     ┆ u32  ┆ u32  │\n",
       "╞═════════════════════╪═════════╪══════╪══════╡\n",
       "│ 2023-04-30 23:00:00 ┆ null    ┆ null ┆ null │\n",
       "└─────────────────────┴─────────┴──────┴──────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe with the last row containing the last date\n",
    "# This will be appended to the public transport passenger data so\n",
    "# that the upsampling will be done up to this datetime.\n",
    "extra_row = (\n",
    "    pl.DataFrame([{\"transition_date\" : datetime.strptime(\"2023-04-30 23:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "                   \"HIGHWAY\" : None,\n",
    "                   \"SEA\" : None,\n",
    "                   \"RAIL\" : None}])\n",
    "    .with_columns(pl.col('transition_date').dt.cast_time_unit('ns'),\n",
    "                  pl.col(['HIGHWAY', 'SEA', 'RAIL']).cast(pl.UInt32))\n",
    ")\n",
    "\n",
    "extra_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_trnsprt_df = (   \n",
    "    # Read parquet\n",
    "    pl.read_parquet(\"datasets/04_tr_public_transport_passengers/tr_ist_public_transport_travel.gz\")\n",
    "\n",
    "    # Convert column to show only date\n",
    "    .with_columns(pl.col('transition_date').dt.date())\n",
    "\n",
    "    # Groupby and aggregate to get sum\n",
    "    .groupby(['transition_date', 'HOUR', 'road_type'], maintain_order=True)\n",
    "    .agg(pl.col('number_of_passenger').sum())\n",
    "\n",
    "    # Pivot to convert road_type categories to columns\n",
    "    .pivot(index=['transition_date', 'HOUR'],\n",
    "           columns='road_type',\n",
    "           values='number_of_passenger')\n",
    "\n",
    "    # Convert HOUR column from integer to time format\n",
    "    .with_columns(pl.col('HOUR')\n",
    "                  .cast(pl.Utf8)\n",
    "                  .apply(lambda x: x.zfill(2) + \":00:00\")\n",
    "                  .str.strptime(pl.Time, fmt=\"%H:%M:%s\"))\n",
    "\n",
    "    # Combine transition_date and HOUR column to get datetime format\n",
    "    .with_columns(pl.col('transition_date').dt.combine(pl.col('HOUR'), time_unit='ns'))\n",
    "\n",
    "    # After resampling, HOUR will have lots of null values, so dropping them for now.\n",
    "    .drop('HOUR')\n",
    "\n",
    "    # Append the last row created.\n",
    "    .extend(extra_row)\n",
    "\n",
    "    # Sort date for proper upsampling\n",
    "    .sort('transition_date')\n",
    "\n",
    "    # Upsampling to get 1 hour frequncy for all days from \n",
    "    # Jan 2020 to 30 April 2023, 23:00 hours\n",
    "    .upsample(time_column='transition_date', every=\"1h\")\n",
    "\n",
    "    # Extracting HOUR & DAYOFWEEK\n",
    "    .with_columns(pl.col('transition_date').dt.hour().alias(\"HOUR\"),\n",
    "                  pl.col('transition_date').dt.weekday().alias(\"DAYOFWEEK\"))\n",
    "\n",
    "    # Sorting by HOUR & DAYOFWEEK. This will ensure capturing \n",
    "    # HOUR and WEEKLY patterns during interpolation\n",
    "    .sort(['HOUR', 'DAYOFWEEK'])\n",
    "\n",
    "    # Interpolating the road_typw=e columns.\n",
    "    # The last row remains null, hence filling by forward fill\n",
    "    .with_columns(pl.col(['HIGHWAY', 'SEA', 'RAIL'])\n",
    "                  .interpolate()\n",
    "                  .forward_fill())\n",
    "\n",
    "    # Sort by datetime to get proper order\n",
    "    .sort('transition_date')\n",
    "\n",
    "    # These columns no longer needed\n",
    "    .drop(['HOUR', 'DAYOFWEEK'])\n",
    "\n",
    "    # Renaming columns\n",
    "    .rename({'transition_date' : 'DATE_TIME',\n",
    "             'HIGHWAY' : 'HIGHWAY_TRNSPRT_PSNGRS',\n",
    "             'SEA' : 'SEA_TRNSPRT_PSNGRS',\n",
    "             'RAIL' : 'RAIL_TRNSPRT_PSNGRS'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>HIGHWAY_TRNSPRT_PSNGRS</th><th>SEA_TRNSPRT_PSNGRS</th><th>RAIL_TRNSPRT_PSNGRS</th></tr><tr><td>datetime[ns]</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>2020-01-01 00:00:00</td><td>15430</td><td>2211</td><td>31247</td></tr><tr><td>2020-01-01 01:00:00</td><td>12108</td><td>1464</td><td>27136</td></tr><tr><td>2020-01-01 02:00:00</td><td>9168</td><td>815</td><td>13970</td></tr><tr><td>2020-01-01 03:00:00</td><td>6585</td><td>517</td><td>8190</td></tr><tr><td>2020-01-01 04:00:00</td><td>5054</td><td>219</td><td>5310</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────┬────────────────────────┬────────────────────┬─────────────────────┐\n",
       "│ DATE_TIME           ┆ HIGHWAY_TRNSPRT_PSNGRS ┆ SEA_TRNSPRT_PSNGRS ┆ RAIL_TRNSPRT_PSNGRS │\n",
       "│ ---                 ┆ ---                    ┆ ---                ┆ ---                 │\n",
       "│ datetime[ns]        ┆ u32                    ┆ u32                ┆ u32                 │\n",
       "╞═════════════════════╪════════════════════════╪════════════════════╪═════════════════════╡\n",
       "│ 2020-01-01 00:00:00 ┆ 15430                  ┆ 2211               ┆ 31247               │\n",
       "│ 2020-01-01 01:00:00 ┆ 12108                  ┆ 1464               ┆ 27136               │\n",
       "│ 2020-01-01 02:00:00 ┆ 9168                   ┆ 815                ┆ 13970               │\n",
       "│ 2020-01-01 03:00:00 ┆ 6585                   ┆ 517                ┆ 8190                │\n",
       "│ 2020-01-01 04:00:00 ┆ 5054                   ┆ 219                ┆ 5310                │\n",
       "└─────────────────────┴────────────────────────┴────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_trnsprt_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID19 Restrictions\n",
    "    Here, a dataset with the dates of official covid restrictions implemented will be created.\n",
    "    Sources: https://en.wikipedia.org/wiki/COVID-19_pandemic_in_Turkey\n",
    "\n",
    "#### COVID Restrictions TimeLine:\n",
    "    * 16th March 2020 to 31st May 2020: Closure of schools, flight ban to some countries, Curfew for those over the age of 65, followed by people twenty and younger, curfew on weekends.\n",
    "\n",
    "    * 20th Nov 2020 to 28th Feb 2021: Curfew on people age 65 and older and people twenty and younger. Businesses and places of worship to halt indoor activities\n",
    "\n",
    "    * 30th March 2021 to 31st May 2021: Reintroduce lockdowns during weekends. Nationwide lockdowns from 29 April 2021 to 17th May. Weekend curfew remains after nationwide lockdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE</th><th>IS_COVID_RESTRICTION</th></tr><tr><td>date</td><td>i64</td></tr></thead><tbody><tr><td>2020-03-16</td><td>1</td></tr><tr><td>2020-03-17</td><td>1</td></tr><tr><td>2020-03-18</td><td>1</td></tr><tr><td>2020-03-19</td><td>1</td></tr><tr><td>2020-03-20</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬──────────────────────┐\n",
       "│ DATE       ┆ IS_COVID_RESTRICTION │\n",
       "│ ---        ┆ ---                  │\n",
       "│ date       ┆ i64                  │\n",
       "╞════════════╪══════════════════════╡\n",
       "│ 2020-03-16 ┆ 1                    │\n",
       "│ 2020-03-17 ┆ 1                    │\n",
       "│ 2020-03-18 ┆ 1                    │\n",
       "│ 2020-03-19 ┆ 1                    │\n",
       "│ 2020-03-20 ┆ 1                    │\n",
       "└────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_dates_list = [\"2020-03-16\", \"2020-11-20\", \"2021-03-30\"] \n",
    "end_dates_list = [\"2020-05-31\", \"2021-02-28\", \"2021-05-31\"]\n",
    "\n",
    "covid_timeline_list = []\n",
    "\n",
    "for start, end in zip(start_dates_list, end_dates_list):\n",
    "    sd = datetime.strptime(start, \"%Y-%m-%d\").date()\n",
    "    ed = datetime.strptime(end, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    date_range = pl.date_range(start=sd, end=ed, interval='1d', eager=True).to_list()\n",
    "\n",
    "    for date in date_range:\n",
    "        covid_timeline_list.append({\n",
    "            'DATE' : date,\n",
    "            'IS_COVID_RESTRICTION' : 1,\n",
    "        })\n",
    "\n",
    "covid_df = pl.DataFrame(covid_timeline_list)\n",
    "covid_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Density Dataset\n",
    "    Putting it all together - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>LATITUDE</th><th>LONGITUDE</th><th>GEOHASH</th><th>AVERAGE_SPEED</th><th>NUMBER_OF_VEHICLES</th><th>CITIZEN_RETURN</th><th>CITIZEN_ARRIVAL</th><th>TOURIST_ARRIVAL</th><th>HOLIDAY_NAME</th><th>HOLIDAY_TYPE</th><th>SCHOOL_HOLIDAY_TYPE</th><th>HIGHWAY_TRNSPRT_PSNGRS</th><th>SEA_TRNSPRT_PSNGRS</th><th>RAIL_TRNSPRT_PSNGRS</th><th>IS_COVID_RESTRICTION</th></tr><tr><td>datetime[ns]</td><td>f32</td><td>f32</td><td>cat</td><td>u8</td><td>u16</td><td>u32</td><td>u32</td><td>u32</td><td>cat</td><td>cat</td><td>cat</td><td>u32</td><td>u32</td><td>u32</td><td>bool</td></tr></thead><tbody><tr><td>2020-01-01 00:00:00</td><td>40.78949</td><td>29.415894</td><td>&quot;sxkbj3&quot;</td><td>72</td><td>97</td><td>627933</td><td>692729</td><td>1017034</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td><td>&quot;Christmas holi…</td><td>15430</td><td>2211</td><td>31247</td><td>false</td></tr><tr><td>2020-01-01 01:00:00</td><td>40.78949</td><td>29.415894</td><td>&quot;sxkbj3&quot;</td><td>74</td><td>58</td><td>627933</td><td>692729</td><td>1017034</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td><td>&quot;Christmas holi…</td><td>12108</td><td>1464</td><td>27136</td><td>false</td></tr><tr><td>2020-01-01 02:00:00</td><td>40.78949</td><td>29.415894</td><td>&quot;sxkbj3&quot;</td><td>79</td><td>40</td><td>627933</td><td>692729</td><td>1017034</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td><td>&quot;Christmas holi…</td><td>9168</td><td>815</td><td>13970</td><td>false</td></tr><tr><td>2020-01-01 03:00:00</td><td>40.78949</td><td>29.415894</td><td>&quot;sxkbj3&quot;</td><td>74</td><td>33</td><td>627933</td><td>692729</td><td>1017034</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td><td>&quot;Christmas holi…</td><td>6585</td><td>517</td><td>8190</td><td>false</td></tr><tr><td>2020-01-01 04:00:00</td><td>40.78949</td><td>29.415894</td><td>&quot;sxkbj3&quot;</td><td>79</td><td>25</td><td>627933</td><td>692729</td><td>1017034</td><td>&quot;New Year&#x27;s Day…</td><td>&quot;National holid…</td><td>&quot;Christmas holi…</td><td>5054</td><td>219</td><td>5310</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌─────────┬──────────┬───────────┬─────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ DATE_TI ┆ LATITUDE ┆ LONGITUDE ┆ GEOHASH ┆ … ┆ HIGHWAY_TR ┆ SEA_TRNSPR ┆ RAIL_TRNSP ┆ IS_COVID_R │\n",
       "│ ME      ┆ ---      ┆ ---       ┆ ---     ┆   ┆ NSPRT_PSNG ┆ T_PSNGRS   ┆ RT_PSNGRS  ┆ ESTRICTION │\n",
       "│ ---     ┆ f32      ┆ f32       ┆ cat     ┆   ┆ RS         ┆ ---        ┆ ---        ┆ ---        │\n",
       "│ datetim ┆          ┆           ┆         ┆   ┆ ---        ┆ u32        ┆ u32        ┆ bool       │\n",
       "│ e[ns]   ┆          ┆           ┆         ┆   ┆ u32        ┆            ┆            ┆            │\n",
       "╞═════════╪══════════╪═══════════╪═════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 2020-01 ┆ 40.78949 ┆ 29.415894 ┆ sxkbj3  ┆ … ┆ 15430      ┆ 2211       ┆ 31247      ┆ false      │\n",
       "│ -01 00: ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 00:00   ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01 ┆ 40.78949 ┆ 29.415894 ┆ sxkbj3  ┆ … ┆ 12108      ┆ 1464       ┆ 27136      ┆ false      │\n",
       "│ -01 01: ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 00:00   ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01 ┆ 40.78949 ┆ 29.415894 ┆ sxkbj3  ┆ … ┆ 9168       ┆ 815        ┆ 13970      ┆ false      │\n",
       "│ -01 02: ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 00:00   ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01 ┆ 40.78949 ┆ 29.415894 ┆ sxkbj3  ┆ … ┆ 6585       ┆ 517        ┆ 8190       ┆ false      │\n",
       "│ -01 03: ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 00:00   ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 2020-01 ┆ 40.78949 ┆ 29.415894 ┆ sxkbj3  ┆ … ┆ 5054       ┆ 219        ┆ 5310       ┆ false      │\n",
       "│ -01 04: ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "│ 00:00   ┆          ┆           ┆         ┆   ┆            ┆            ┆            ┆            │\n",
       "└─────────┴──────────┴───────────┴─────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "td_df = (\n",
    "    # Scan TD density file\n",
    "    pl.scan_parquet(\"datasets/01_tr_density/ist_traffic_density_rev03.zstd\")\n",
    "\n",
    "    .drop(['MINIMUM_SPEED', 'MAXIMUM_SPEED'])\n",
    "\n",
    "    # Create datetime features and downcast datatype\n",
    "    .with_columns(pl.col(\"DATE_TIME\").dt.date().alias(\"DATE\"),\n",
    "                  pl.col(\"DATE_TIME\").dt.month().alias(\"MONTH\").cast(pl.UInt8),\n",
    "                  pl.col(\"DATE_TIME\").dt.year().alias(\"YEAR\").cast(pl.UInt16),\n",
    "                  pl.col(\"DATE_TIME\").dt.hour().alias(\"HOUR\").cast(pl.UInt8))\n",
    "\n",
    "    # left join citizen travel dataset\n",
    "    .join(cz_df.lazy(), on=[\"YEAR\", \"MONTH\"], how=\"left\")\n",
    "\n",
    "    # left join tourist arrival dataset\n",
    "    .join(tr_df.lazy(), on=[\"YEAR\", \"MONTH\"], how=\"left\")\n",
    "\n",
    "    # left join holiday df and fill missing value in holiday name and type columns with \"Non Holiday\" category\n",
    "    .join(hol_df.lazy(), on='DATE', how='left')\n",
    "    .with_columns(pl.col(['HOLIDAY_NAME', 'HOLIDAY_TYPE']).fill_null(\"Non Holiday\"))\n",
    "\n",
    "    # left join school holidays and fill missing value in school holidays with \"Non Holiday\" category\n",
    "    .join(all_school_holidays.lazy(), on='DATE', how='left')\n",
    "    .with_columns(pl.col('SCHOOL_HOLIDAY_TYPE').fill_null(\"Non Holiday\"))\n",
    "\n",
    "    # left join public transport passenger data\n",
    "    .join(pub_trnsprt_df.lazy(), on='DATE_TIME', how='left')\n",
    "\n",
    "    # left join covid_df\n",
    "    .join(covid_df.lazy(), on='DATE', how='left')\n",
    "\n",
    "    # Cast all categorical columns to pl.Categorical datatype\n",
    "    .with_columns(pl.col(['HOLIDAY_NAME', 'HOLIDAY_TYPE', 'SCHOOL_HOLIDAY_TYPE', 'GEOHASH']).cast(pl.Categorical),\n",
    "                  pl.col('IS_COVID_RESTRICTION').fill_null(0).cast(pl.Boolean))\n",
    "\n",
    "    # Drop DATE column\n",
    "    .drop(['DATE', 'MONTH', 'YEAR', 'HOUR'])\n",
    "    \n",
    ").collect(streaming=True)\n",
    "\n",
    "td_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE_TIME</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATITUDE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LONGITUDE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOHASH</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVERAGE_SPEED</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMBER_OF_VEHICLES</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CITIZEN_RETURN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CITIZEN_ARRIVAL</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOURIST_ARRIVAL</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOLIDAY_NAME</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOLIDAY_TYPE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHOOL_HOLIDAY_TYPE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIGHWAY_TRNSPRT_PSNGRS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEA_TRNSPRT_PSNGRS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAIL_TRNSPRT_PSNGRS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS_COVID_RESTRICTION</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        null_counts\n",
       "DATE_TIME                         0\n",
       "LATITUDE                          0\n",
       "LONGITUDE                         0\n",
       "GEOHASH                           0\n",
       "AVERAGE_SPEED                     0\n",
       "NUMBER_OF_VEHICLES                0\n",
       "CITIZEN_RETURN                    0\n",
       "CITIZEN_ARRIVAL                   0\n",
       "TOURIST_ARRIVAL                   0\n",
       "HOLIDAY_NAME                      0\n",
       "HOLIDAY_TYPE                      0\n",
       "SCHOOL_HOLIDAY_TYPE               0\n",
       "HIGHWAY_TRNSPRT_PSNGRS            0\n",
       "SEA_TRNSPRT_PSNGRS                0\n",
       "RAIL_TRNSPRT_PSNGRS               0\n",
       "IS_COVID_RESTRICTION              0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null counts by column\n",
    "(\n",
    "    td_df\n",
    "    .null_count()\n",
    "    .to_pandas().T\n",
    "    .rename(columns={0 : \"null_counts\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME : Datetime(time_unit='ns', time_zone=None)\n",
      "LATITUDE : Float32\n",
      "LONGITUDE : Float32\n",
      "GEOHASH : Categorical\n",
      "AVERAGE_SPEED : UInt8\n",
      "NUMBER_OF_VEHICLES : UInt16\n",
      "CITIZEN_RETURN : UInt32\n",
      "CITIZEN_ARRIVAL : UInt32\n",
      "TOURIST_ARRIVAL : UInt32\n",
      "HOLIDAY_NAME : Categorical\n",
      "HOLIDAY_TYPE : Categorical\n",
      "SCHOOL_HOLIDAY_TYPE : Categorical\n",
      "HIGHWAY_TRNSPRT_PSNGRS : UInt32\n",
      "SEA_TRNSPRT_PSNGRS : UInt32\n",
      "RAIL_TRNSPRT_PSNGRS : UInt32\n",
      "IS_COVID_RESTRICTION : Boolean\n"
     ]
    }
   ],
   "source": [
    "for k, v in td_df.schema.items():\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Size of merged df: 2.914 GB\n",
      "Dataset Shape: 52,910,592 rows, 16 columns\n"
     ]
    }
   ],
   "source": [
    "# Merged dataset information\n",
    "print(f'Estimated Size of merged df: {td_df.estimated_size(\"gb\"):.3f} GB')\n",
    "print(f'Dataset Shape: {td_df.shape[0]:,} rows, {td_df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DATE_TIME</th><th>GEOHASH</th><th>MINIMUM_SPEED</th><th>MAXIMUM_SPEED</th></tr><tr><td>datetime[ns]</td><td>cat</td><td>u8</td><td>u8</td></tr></thead><tbody><tr><td>2020-01-01 00:00:00</td><td>&quot;sxkbj3&quot;</td><td>128</td><td>10</td></tr><tr><td>2020-01-01 01:00:00</td><td>&quot;sxkbj3&quot;</td><td>149</td><td>7</td></tr><tr><td>2020-01-01 02:00:00</td><td>&quot;sxkbj3&quot;</td><td>137</td><td>36</td></tr><tr><td>2020-01-01 03:00:00</td><td>&quot;sxkbj3&quot;</td><td>124</td><td>42</td></tr><tr><td>2020-01-01 04:00:00</td><td>&quot;sxkbj3&quot;</td><td>115</td><td>14</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────┬─────────┬───────────────┬───────────────┐\n",
       "│ DATE_TIME           ┆ GEOHASH ┆ MINIMUM_SPEED ┆ MAXIMUM_SPEED │\n",
       "│ ---                 ┆ ---     ┆ ---           ┆ ---           │\n",
       "│ datetime[ns]        ┆ cat     ┆ u8            ┆ u8            │\n",
       "╞═════════════════════╪═════════╪═══════════════╪═══════════════╡\n",
       "│ 2020-01-01 00:00:00 ┆ sxkbj3  ┆ 128           ┆ 10            │\n",
       "│ 2020-01-01 01:00:00 ┆ sxkbj3  ┆ 149           ┆ 7             │\n",
       "│ 2020-01-01 02:00:00 ┆ sxkbj3  ┆ 137           ┆ 36            │\n",
       "│ 2020-01-01 03:00:00 ┆ sxkbj3  ┆ 124           ┆ 42            │\n",
       "│ 2020-01-01 04:00:00 ┆ sxkbj3  ┆ 115           ┆ 14            │\n",
       "└─────────────────────┴─────────┴───────────────┴───────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a separate dataset for min speed and max speed\n",
    "min_max_speed_df = (\n",
    "    pl.scan_parquet(\"datasets/01_tr_density/ist_traffic_density_rev03.zstd\")\n",
    "    .select(['DATE_TIME', 'GEOHASH', 'MINIMUM_SPEED', 'MAXIMUM_SPEED'])\n",
    "    .with_columns(pl.col('GEOHASH').cast(pl.Categorical))\n",
    ").collect(streaming=True)\n",
    "\n",
    "min_max_speed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Size of Min-Max speed dataset: 706.484 MB\n",
      "Dataset Shape: 52,910,592 rows, 4 columns\n"
     ]
    }
   ],
   "source": [
    "# Min Max dataset information\n",
    "print(f'Estimated Size of Min-Max speed dataset: {min_max_speed_df.estimated_size(\"mb\"):.3f} MB')\n",
    "print(f'Dataset Shape: {min_max_speed_df.shape[0]:,} rows, {min_max_speed_df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving traffic Density dataset to parquet\n",
    "td_df.write_parquet(\"datasets/00_tr_df_merged/tr_ist_td_merged_01_ver01.zstd\", compression=\"zstd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving min_max_speed_df dataset to parquet\n",
    "min_max_speed_df.write_parquet(\"datasets/00_tr_df_merged/tr_ist_td_min_max_speed.zstd\", compression=\"zstd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
